{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika SIiB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvXS6QacVr3J"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dNx4QtRAZ0k"
      },
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m--n6Hjjeggf"
      },
      "source": [
        "#Clear\n",
        "rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCxRlLUalxLk"
      },
      "source": [
        "**Data loader class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xet2JAsQDEFG"
      },
      "source": [
        "class Data(object):\n",
        "\n",
        "  def __init__(self, path):\n",
        "      #Initial size of images == 150x150x3\n",
        "      self.image_paths = path\n",
        "      self.labels = self.get_labels(path)\n",
        "  \n",
        "  def get_labels(self, path):  \n",
        "      classes = ['cabrio', 'kombi', 'sedan', 'hatchback', 'luxury-sport', 'SUV', 'pickup']\n",
        "      labels = []\n",
        "      for p in path:\n",
        "        word_label = p.split('_')[0]\n",
        "        word_label = word_label.split('/')\n",
        "        labels.append(classes.index(word_label[-1]))\n",
        "      return labels\n",
        "\n",
        "  def parse_image(self, path, labels):\n",
        "      image = tf.io.read_file(path) \n",
        "      image = tf.image.decode_png(image, channels=3)  \n",
        "      image = tf.image.convert_image_dtype(image, tf.float32) \n",
        "      return image, labels\n",
        "  \n",
        "  def rotate_image(self, image, labels):\n",
        "      image = tfa.image.rotate(image, 0.1745)\n",
        "      image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "      return image, labels\n",
        "  \n",
        "  def flip_image(self, image, labels):\n",
        "      image = tf.image.flip_left_right(image)\n",
        "      return image, labels\n",
        "  \n",
        "  def dataset(self, batch_size, threads=4):\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((self.image_paths, self.labels))\n",
        "      dataset = dataset.map(self.parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "      flip = dataset.map(self.flip_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "      dataset = dataset.concatenate(flip)\n",
        "\n",
        "      rotate = dataset.map(self.rotate_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "      dataset = dataset.concatenate(rotate)\n",
        "\n",
        "      dataset = dataset.shuffle(30000).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)      \n",
        "      return dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DCoIHI1mDZ9"
      },
      "source": [
        "**Gather dataset and split into train/validation/test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMhzu2nyDMTR"
      },
      "source": [
        "img_list = glob.glob('/content/drive/MyDrive/carsdata2/train/*.png')\n",
        "rest_of_images = glob.glob('/content/drive/MyDrive/carsdata2/test2/*.png')\n",
        "\n",
        "for i in rest_of_images:\n",
        "  img_list.append(i)\n",
        "\n",
        "log_dir = \"logs/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "dataset = Data(img_list).dataset(BATCH_SIZE)\n",
        "\n",
        "DATASET_SIZE = len(dataset)\n",
        "\n",
        "train_size = int(0.8 * DATASET_SIZE)\n",
        "val_size = int(0.1 * DATASET_SIZE)\n",
        "test_size = int(0.1 * DATASET_SIZE)\n",
        "\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)\n",
        "val_dataset = test_dataset.skip(val_size)\n",
        "test_dataset = test_dataset.take(test_size)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsfQdVOOmN21"
      },
      "source": [
        "**Neural network architecture - using ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6tHs02DdN1M"
      },
      "source": [
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = keras.layers.MaxPooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = keras.layers.Flatten(name=\"flatten\")(headModel)\n",
        "headModel = keras.layers.Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "headModel = keras.layers.Dense(7, activation=\"softmax\")(headModel)\n",
        "\n",
        "model = keras.models.Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE4_MjrVbMvP"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK5voTGbmMM2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5DlwZnyqvYf"
      },
      "source": [
        "model.fit(train_dataset, epochs=50, validation_data=val_dataset, callbacks=[es, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvAaq3ByR3Fv"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HILLIICfq7gq"
      },
      "source": [
        "model.save('cars_resnet.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcyX-rfdfzdv"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}